# Ollama Model Tool Support Analysis Report
Test Date: 2025-05-05 01:11:47

## Summary
- Total models tested: 18
- Native tool support successes: 5 (27.8%)
- Alternative method successes: 12
- Interface method successes: 13

## Basic Tool Calling Support
| Model | Success | Reason |
|-------|---------|--------|
| llama3:8b | False | No tool calls; composite fallback run |
| nomic-embed-text:latest | False | No tool calls; composite fallback run |
| qwq:32b | True | Native tool call succeeded |
| deepseek-r1:32b | False | No tool calls; composite fallback run |
| mistral-small:24b | True | Native tool call succeeded |
| llava-phi3:latest | False | No tool calls; composite fallback run |
| minicpm-v:latest | False | No tool calls; composite fallback run |
| long-gemma:latest | False | No tool calls; composite fallback run |
| llama3.1:8b | True | Native tool call succeeded |
| phi3:14b-medium-128k-instruct-q8_0 | False | No tool calls; composite fallback run |
| moondream:latest | False | No tool calls; composite fallback run |
| llava:latest | False | No tool calls; composite fallback run |
| llama3.2-vision:11b | False | No tool calls; composite fallback run |
| qwen2.5:0.5b | True | Native tool call succeeded |
| gemma2:2b | False | No tool calls; composite fallback run |
| llama3.2:latest | True | Native tool call succeeded |
| gemma2:9b | False | No tool calls; composite fallback run |
| bespoke-minicheck:latest | False | No tool calls; composite fallback run |

## Advanced Testing Results
### qwq:32b
- **complex_query**: ✅ None <think> Okay, the user wants me to compare the populations of Tokyo and New York
- **multi_tool**: ✅ None <think> Okay, so the user wants information comparing Tokyo's transportation sys
- **chain_of_thought**: ✅ None <think> Okay, the user wants a 5-day trip plan for Tokyo focusing on mild weathe

### mistral-small:24b
- **complex_query**: ✅ None I'm unable to retrieve the current population data for Tokyo and New York City d
- **multi_tool**: ✅ None I'm sorry, I couldn't retrieve the information you requested. Let me try an alte
- **chain_of_thought**: ✅ None I'm sorry, I couldn't retrieve the information about the best time to visit Toky

### llama3.1:8b
- **complex_query**: ✅ None A comparison of the populations of Tokyo and New York City!  According to the la
- **multi_tool**: ✅ None Tokyo's transportation system is one of the most efficient and extensive in the 
- **chain_of_thought**: ✅ None The best time for a mild weather trip to Tokyo is from March to May or September

### qwen2.5:0.5b
- **complex_query**: ❌ No tool calls made 
- **multi_tool**: ❌ No tool calls made 
- **chain_of_thought**: ❌ No tool calls made 

### llama3.2:latest
- **complex_query**: ✅ None I'm sorry, but I cannot provide you with the population of Tokyo and New York Ci
- **multi_tool**: ✅ None I apologize, but it seems like there was an error in my search. However, I can p
- **chain_of_thought**: ✅ None I'm sorry, but I cannot provide information about the best time for mild weather

## Alternative Methods Results
### llama3:8b
- **direct_json**: ✅ None It looks like the search didn't go as planned!  Here's another attempt:  {"actio
- **alternate_search**: ✅ None It looks like you're getting an error message from a Python script that's trying

### nomic-embed-text:latest
- **direct_json**: ❌ No JSON found 
- **alternate_search**: ❌ No response 

### deepseek-r1:32b
- **direct_json**: ❌ No JSON found 
- **alternate_search**: ✅ None <think> Okay, so I'm trying to find the population of Tokyo in 2025, but when I 

### llava-phi3:latest
- **direct_json**: ❌ No JSON found 
- **alternate_search**: ✅ None It looks like there was an error when trying to access the DuckDuckGo API for in

### minicpm-v:latest
- **direct_json**: ✅ None I'm sorry, but I was unable to retrieve the Tokyo population from DuckDuckGo API
- **alternate_search**: ✅ None Based on the error message, it seems that there was an issue with connecting to 

### long-gemma:latest
- **direct_json**: ✅ None Okay, I'm having trouble connecting to the DuckDuckGo API.    Could you please t
- **alternate_search**: ✅ None The error message indicates that your code is trying to connect to the DuckDuckG

### phi3:14b-medium-128k-instruct-q8_0
- **direct_json**: ❌ No JSON found 
- **alternate_search**: ✅ None The search results indicate that the user was trying to fetch data from DuckDuck

### moondream:latest
- **direct_json**: ✅ None   [{"action": "search", "query": "Tokyo population"}]
- **alternate_search**: ❌ No response 

### llava:latest
- **direct_json**: ❌ No JSON found 
- **alternate_search**: ✅ None  It appears that you are trying to access the DuckDuckGo API to retrieve informa

### llama3.2-vision:11b
- **direct_json**: ❌ None 
- **alternate_search**: ✅ None It looks like you're getting an error message when trying to access the DuckDuck

### gemma2:2b
- **direct_json**: ✅ None ```json {"error": "Search Error", "message": "Search error: HTTPSConnectionPool(
- **alternate_search**: ✅ None This error message indicates a problem connecting to the DuckDuckGo API server, 

### gemma2:9b
- **direct_json**: ✅ None ```json {"action": "error", "message": "Search error: HTTPSConnectionPool(host='
- **alternate_search**: ✅ None The error message you're seeing indicates that your program is having trouble co

### bespoke-minicheck:latest
- **direct_json**: ❌ No JSON found 
- **alternate_search**: ✅ None No

## Interface (LLama) Results
- **llama3:8b**: ✅ None <think> Okay, the user wants me to act as a caller by first searching for Tokyo'
- **nomic-embed-text:latest**: ✅ None <think> Okay, so the user asked me to act as a caller by searching for Tokyo's p
- **deepseek-r1:32b**: ✅ None <think> Okay, the user wants me to act as a caller, search for Tokyo's populatio
- **llava-phi3:latest**: ✅ None <think> Okay, the user wants me to act as a caller by first searching for Tokyo'
- **minicpm-v:latest**: ✅ None <think> Okay, so the user wants me to act as a caller and first search for Tokyo
- **long-gemma:latest**: ✅ None <think> Okay, so I need to act as a caller and first search for Tokyo's populati
- **phi3:14b-medium-128k-instruct-q8_0**: ✅ None <think> Okay, the user wants me to act as a caller and search for Tokyo's popula
- **moondream:latest**: ✅ None <think> Okay, so the user wants me to act as a caller and search for Tokyo's pop
- **llava:latest**: ✅ None <think> Okay, the user asked me to act as a caller by searching for Tokyo's popu
- **llama3.2-vision:11b**: ✅ None <think> Okay, let's tackle this step by step. The user wants me to act as a call
- **gemma2:2b**: ✅ None <think> Okay, the user wants me to act as a caller by searching Tokyo's populati
- **gemma2:9b**: ✅ None <think> Okay, so the user wants me to act as a caller, first by searching for To
- **bespoke-minicheck:latest**: ✅ None <think> Okay, so the user wants me to act as a caller and search for Tokyo's pop